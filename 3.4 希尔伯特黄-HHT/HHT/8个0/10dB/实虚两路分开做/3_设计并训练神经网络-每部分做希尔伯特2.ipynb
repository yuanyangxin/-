{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "# from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "import torch.optim as optim\n",
    "# import os\n",
    "import time\n",
    "\n",
    "import loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日志记录模块2\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level = logging.INFO)\n",
    "handler = logging.FileHandler(\"./每部分做希尔伯特-2.log\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(handler)\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMgidBKKLq7s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7db90c5bd0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7e9f5efc90>\n"
     ]
    }
   ],
   "source": [
    "transforms = tv.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "numOfBatch = 9\n",
    "pixel = 64\n",
    "flag = 0\n",
    "root = f'./{numOfBatch}/data'\n",
    "batchSize = 4\n",
    "train_data = loadData.MyDataset(txt=f'files_train10-每部分做希尔伯特.txt', transform=None)\n",
    "test_data = loadData.MyDataset(txt=f'files_test10-每部分做希尔伯特.txt', transform=None)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "print(train_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6h-TJ16XLq7y",
    "outputId": "d4f641b6-e9d4-4aa4-8672-13c98099eb01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6426\n",
      "419\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "CSdZoIqDLq7-",
    "outputId": "22fd354b-1be5-4f7d-e772-7873db328b62"
   },
   "outputs": [],
   "source": [
    "# data = iter(train_loader)\n",
    "\n",
    "# # print(type(data))\n",
    "# # print(len(data))\n",
    "# data_, label = data.next()\n",
    "# print(train_loader.batch_size)\n",
    "# print(data_.shape)\n",
    "# # print(label)\n",
    "# # print(data_, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 1189, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 1, 1200, 2).float()\n",
    "conv = nn.Conv2d(in_channels = 1, out_channels = 128, kernel_size = (10, 1))\n",
    "x = conv(x)\n",
    "x.shape\n",
    "conv2 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = (3, 2))\n",
    "x = conv2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256*1189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZSua6ALLq8I"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3, 10))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (2, 3))\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(20304, 10240)\n",
    "        self.fc2 = nn.Linear(10240, 500)\n",
    "        self.fc3 = nn.Linear(500, 54)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1)\n",
    "    \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "# from tensorboardX import SummaryWriter\n",
    "# net = Net()\n",
    "# # writer = SummaryWriter('writer928') #建立一个保存数据用的东西\n",
    "# dummy_input = torch.rand(2,160,400)  # 假设输入20张1*28*28的图片\n",
    "# with SummaryWriter(comment='Net1') as w:\n",
    "#     w.add_graph(net, (dummy_input,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBWBdr1LLq82"
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "epochs = 1500\n",
    "average_loss_series = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "87bfeNToLq87",
    "outputId": "af954cd8-8959-4212-ff89-482e57c90d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 4, 1280])\n"
     ]
    }
   ],
   "source": [
    "for a, b in enumerate(train_loader):\n",
    "    inputs, labels = b\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_c6Gwp3ALq9k",
    "outputId": "60864ad5-6b9b-4875-a39f-9600521d3629",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[1, 1000] loss: 3.98820131111145\n",
      "设备号为: tensor([53,  4, 15, 29], device='cuda:0')，预测的设备号为:tensor([38, 32, 20,  1], device='cuda:0')\n",
      "[1, 1000] acc: 0.019750000908970833\n",
      "[2, 1000] loss: 3.978781323671341\n",
      "设备号为: tensor([40, 50, 23, 35], device='cuda:0')，预测的设备号为:tensor([29, 42, 42, 45], device='cuda:0')\n",
      "[2, 1000] acc: 0.027250001206994057\n",
      "[3, 1000] loss: 3.9610574786663055\n",
      "设备号为: tensor([29, 32,  1, 48], device='cuda:0')，预测的设备号为:tensor([29, 29, 29,  5], device='cuda:0')\n",
      "[3, 1000] acc: 0.04325000196695328\n",
      "[4, 1000] loss: 3.8936173114776613\n",
      "设备号为: tensor([31, 24,  6, 21], device='cuda:0')，预测的设备号为:tensor([29, 37,  9, 18], device='cuda:0')\n",
      "[4, 1000] acc: 0.05625000223517418\n",
      "[5, 1000] loss: 3.5709230070114137\n",
      "设备号为: tensor([40, 35,  1,  4], device='cuda:0')，预测的设备号为:tensor([24, 32, 32, 34], device='cuda:0')\n",
      "[5, 1000] acc: 0.0637500062584877\n",
      "[6, 1000] loss: 3.2363443958759306\n",
      "设备号为: tensor([ 8, 13,  2, 27], device='cuda:0')，预测的设备号为:tensor([ 9, 53,  7, 11], device='cuda:0')\n",
      "[6, 1000] acc: 0.09050000458955765\n",
      "[7, 1000] loss: 3.0345471450090407\n",
      "设备号为: tensor([ 8,  6, 24, 46], device='cuda:0')，预测的设备号为:tensor([ 8,  8, 24, 52], device='cuda:0')\n",
      "[7, 1000] acc: 0.12250000238418579\n",
      "[8, 1000] loss: 2.8891455556154253\n",
      "设备号为: tensor([13, 33,  5, 12], device='cuda:0')，预测的设备号为:tensor([42,  9,  6, 24], device='cuda:0')\n",
      "[8, 1000] acc: 0.14800000190734863\n",
      "[9, 1000] loss: 2.694819632291794\n",
      "设备号为: tensor([52, 45, 16, 16], device='cuda:0')，预测的设备号为:tensor([45, 44, 40, 50], device='cuda:0')\n",
      "[9, 1000] acc: 0.17900000512599945\n",
      "[10, 1000] loss: 2.5632950459718704\n",
      "设备号为: tensor([25, 10, 11, 23], device='cuda:0')，预测的设备号为:tensor([ 2, 11, 31, 37], device='cuda:0')\n",
      "[10, 1000] acc: 0.21050001680850983\n",
      "[11, 1000] loss: 2.3715362550616264\n",
      "设备号为: tensor([15, 39, 17, 21], device='cuda:0')，预测的设备号为:tensor([15, 31, 48, 18], device='cuda:0')\n",
      "[11, 1000] acc: 0.2527500092983246\n",
      "[12, 1000] loss: 2.21063605761528\n",
      "设备号为: tensor([ 8, 40, 38, 29], device='cuda:0')，预测的设备号为:tensor([ 0, 50,  1, 27], device='cuda:0')\n",
      "[12, 1000] acc: 0.29350000619888306\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "#             print(\"i:\", i )\n",
    "#             print(\"data: \", data[0])\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "#             inputs = inputs.permute(0, 2, 1)\n",
    "            \n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32, device = device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total = labels.size(0)\n",
    "#             print('原来的值:{0}, 预测的值:{1}'.format(labels, predicted))\n",
    "            running_correct = (predicted == labels).sum()\n",
    "            running_acc += running_correct\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 每loopNum个batch打印一次训练状态\n",
    "            loopNum = 1000\n",
    "            if i % loopNum == loopNum - 1:\n",
    "                average_loss = running_loss / loopNum\n",
    "                logger.info('[{0}, {1}] loss: {2}'.format(epoch + 1, i + 1, average_loss))\n",
    "                logger.info('设备号为: {0}，预测的设备号为:{1}'.format(labels, predicted))\n",
    "#                 logger.info(torch.cuda.current_device ())\n",
    "                running_acc = running_acc.float()\n",
    "                average_acc = running_acc / loopNum / total\n",
    "                \n",
    "                logger.info('[{0}, {1}] acc: {2}'.format(epoch + 1, i + 1, average_acc))\n",
    "                average_loss_series.append(average_loss)\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "\n",
    "    x = range(0, len(average_loss_series))\n",
    "    plt.figure()\n",
    "    plt.plot(x, average_loss_series)\n",
    "#     plt.savefig(\"Loss.png\")\n",
    "    plt.savefig(\"Loss.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # %%\n",
    "    # 在测试集上测试\n",
    "    realLabel = []\n",
    "    predictedLabel = []\n",
    "\n",
    "    def correct_rate(net, testloader):\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        count = 0\n",
    "        correctpredict = 0\n",
    "\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device),labels.to(device)\n",
    "            realLabel.append([int(label) for label in labels])\n",
    "    \n",
    "            tests = torch.tensor(images, dtype=torch.float32,device=device)\n",
    "            outputs = net(tests)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            logger.info('设备号为: {0}，模型训练后得到的设备号为:{1}'.format(labels, predicted))\n",
    "#             deviceNumber = torch.cuda.current_device ()\n",
    "#             logger.info(deviceNumber)\n",
    "            \n",
    "            labelsn = labels.cpu().numpy()\n",
    "            pn = predicted.cpu().numpy()\n",
    "            count += len(labelsn)\n",
    "            \n",
    "            for i in range(len(labelsn)):\n",
    "                if labelsn[i] == pn[i]:\n",
    "                    correctpredict += 1\n",
    "                \n",
    "            \n",
    "            logger.info('目前一共测试了{0}组，预测成功的一共有{1}组'.format(count, correctpredict))\n",
    "            predictedLabel.append([int(label) for label in predicted])\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "            \n",
    "        logger.info(\"total的值为：{total}\")\n",
    "#         return 100 * correct  # / total\n",
    "        return 100 * correct/ total \n",
    "\n",
    "\n",
    "    correct = correct_rate(net, test_loader)\n",
    "    logger.info(f'{len(test_loader) * 3}张测试集中准确率为： {correct}%')\n",
    "\n",
    "    # %%\n",
    "    import itertools\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    realLabel = list(itertools.chain.from_iterable(realLabel))\n",
    "    predictedLabel = list(itertools.chain.from_iterable(predictedLabel))\n",
    "\n",
    "    cm = confusion_matrix(realLabel, predictedLabel)\n",
    "    logger.info(cm)\n",
    "\n",
    "#     logger.info('the running time is:{1}'.format(time.time() - startTime))\n",
    "    torch.save(net.state_dict(), f'./model_每部分做希尔伯特_1.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5YnF55DLq90"
   },
   "outputs": [],
   "source": [
    "aa = iter(train_loader)\n",
    "a, b = aa.next()\n",
    "print(a[0].shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(20, 16, 50, 100)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2=nn.Conv2d(16,33,(3,5),stride=(2,1),padding=(4,2))\n",
    "inpu1=Variable(torch.randn(20,16,50,100))\n",
    "print(inpu1.shape)\n",
    "output=m2(inpu1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, len(average_loss_series))\n",
    "plt.figure()\n",
    "plt.plot(x, average_loss_series)\n",
    "plt.savefig(\"Loss-每部分做希尔伯特-1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "3_设计并训练神经网络.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
