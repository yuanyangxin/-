{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "# from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "import torch.optim as optim\n",
    "# import os\n",
    "import time\n",
    "\n",
    "import loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日志记录模块2\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level = logging.INFO)\n",
    "handler = logging.FileHandler(\"./每部分做希尔伯特-3.log\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(handler)\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMgidBKKLq7s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f01ac7dff50>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f01ac7df190>\n"
     ]
    }
   ],
   "source": [
    "transforms = tv.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "numOfBatch = 9\n",
    "pixel = 64\n",
    "flag = 0\n",
    "root = f'./{numOfBatch}/data'\n",
    "batchSize = 4\n",
    "train_data = loadData.MyDataset(txt=f'files_train10-每部分做希尔伯特.txt', transform=None)\n",
    "test_data = loadData.MyDataset(txt=f'files_test10-每部分做希尔伯特.txt', transform=None)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "print(train_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6h-TJ16XLq7y",
    "outputId": "d4f641b6-e9d4-4aa4-8672-13c98099eb01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6426\n",
      "419\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "CSdZoIqDLq7-",
    "outputId": "22fd354b-1be5-4f7d-e772-7873db328b62"
   },
   "outputs": [],
   "source": [
    "# data = iter(train_loader)\n",
    "\n",
    "# # print(type(data))\n",
    "# # print(len(data))\n",
    "# data_, label = data.next()\n",
    "# print(train_loader.batch_size)\n",
    "# print(data_.shape)\n",
    "# # print(label)\n",
    "# # print(data_, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 1189, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 1, 1200, 2).float()\n",
    "conv = nn.Conv2d(in_channels = 1, out_channels = 128, kernel_size = (10, 1))\n",
    "x = conv(x)\n",
    "x.shape\n",
    "conv2 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = (3, 2))\n",
    "x = conv2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256*1189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZSua6ALLq8I"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3, 10))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (2, 10))\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(20192, 10240)\n",
    "        self.fc2 = nn.Linear(10240, 500)\n",
    "        self.fc3 = nn.Linear(500, 54)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1)\n",
    "    \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "# from tensorboardX import SummaryWriter\n",
    "# net = Net()\n",
    "# # writer = SummaryWriter('writer928') #建立一个保存数据用的东西\n",
    "# dummy_input = torch.rand(2,160,400)  # 假设输入20张1*28*28的图片\n",
    "# with SummaryWriter(comment='Net1') as w:\n",
    "#     w.add_graph(net, (dummy_input,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBWBdr1LLq82"
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "epochs = 1500\n",
    "average_loss_series = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "87bfeNToLq87",
    "outputId": "af954cd8-8959-4212-ff89-482e57c90d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 4, 1280])\n"
     ]
    }
   ],
   "source": [
    "for a, b in enumerate(train_loader):\n",
    "    inputs, labels = b\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_c6Gwp3ALq9k",
    "outputId": "60864ad5-6b9b-4875-a39f-9600521d3629",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "[1, 1000] loss: 3.9885730347633364\n",
      "设备号为: tensor([45, 32, 38, 34], device='cuda:1')，预测的设备号为:tensor([31, 25,  2, 30], device='cuda:1')\n",
      "[1, 1000] acc: 0.01875000074505806\n",
      "[2, 1000] loss: 3.9848603575229644\n",
      "设备号为: tensor([15, 44, 18, 21], device='cuda:1')，预测的设备号为:tensor([ 7, 37, 15,  7], device='cuda:1')\n",
      "[2, 1000] acc: 0.01875000074505806\n",
      "[3, 1000] loss: 3.9767272427082063\n",
      "设备号为: tensor([37, 21, 23, 48], device='cuda:1')，预测的设备号为:tensor([12, 17, 41, 17], device='cuda:1')\n",
      "[3, 1000] acc: 0.030000001192092896\n",
      "[4, 1000] loss: 3.958636757135391\n",
      "设备号为: tensor([11,  8, 29, 18], device='cuda:1')，预测的设备号为:tensor([ 8, 14, 19, 12], device='cuda:1')\n",
      "[4, 1000] acc: 0.039250001311302185\n",
      "[5, 1000] loss: 3.880290555238724\n",
      "设备号为: tensor([ 3, 14, 15,  9], device='cuda:1')，预测的设备号为:tensor([ 0, 44, 52,  0], device='cuda:1')\n",
      "[5, 1000] acc: 0.06424999982118607\n",
      "[6, 1000] loss: 3.4730301570892332\n",
      "设备号为: tensor([34, 28,  4, 40], device='cuda:1')，预测的设备号为:tensor([34, 32, 41, 24], device='cuda:1')\n",
      "[6, 1000] acc: 0.0767500028014183\n",
      "[7, 1000] loss: 3.156672628164291\n",
      "设备号为: tensor([52, 26, 48, 48], device='cuda:1')，预测的设备号为:tensor([45, 32,  2, 29], device='cuda:1')\n",
      "[7, 1000] acc: 0.10875000804662704\n",
      "[8, 1000] loss: 2.9573227237463\n",
      "设备号为: tensor([23, 43, 34, 34], device='cuda:1')，预测的设备号为:tensor([53, 16, 31, 34], device='cuda:1')\n",
      "[8, 1000] acc: 0.13300000131130219\n",
      "[9, 1000] loss: 2.8126845560073854\n",
      "设备号为: tensor([ 0, 11, 32,  9], device='cuda:1')，预测的设备号为:tensor([38,  8, 32,  0], device='cuda:1')\n",
      "[9, 1000] acc: 0.15000000596046448\n",
      "[10, 1000] loss: 2.6793075129389763\n",
      "设备号为: tensor([16, 33, 44, 10], device='cuda:1')，预测的设备号为:tensor([22, 33, 52, 31], device='cuda:1')\n",
      "[10, 1000] acc: 0.1837500035762787\n",
      "[11, 1000] loss: 2.568044200539589\n",
      "设备号为: tensor([11, 27,  7, 27], device='cuda:1')，预测的设备号为:tensor([ 3, 33,  7,  3], device='cuda:1')\n",
      "[11, 1000] acc: 0.19325001537799835\n",
      "[12, 1000] loss: 2.4407481433153153\n",
      "设备号为: tensor([27, 31, 37, 52], device='cuda:1')，预测的设备号为:tensor([29, 25, 37, 46], device='cuda:1')\n",
      "[12, 1000] acc: 0.21925000846385956\n",
      "[13, 1000] loss: 2.293938756287098\n",
      "设备号为: tensor([ 1, 22,  0, 46], device='cuda:1')，预测的设备号为:tensor([ 8, 40,  0, 15], device='cuda:1')\n",
      "[13, 1000] acc: 0.2680000066757202\n",
      "[14, 1000] loss: 2.1142076300382615\n",
      "设备号为: tensor([19, 19, 33, 30], device='cuda:1')，预测的设备号为:tensor([51, 21,  1, 30], device='cuda:1')\n",
      "[14, 1000] acc: 0.30900001525878906\n",
      "[15, 1000] loss: 1.9745207443237305\n",
      "设备号为: tensor([28, 31, 21, 45], device='cuda:1')，预测的设备号为:tensor([28, 48, 21, 45], device='cuda:1')\n",
      "[15, 1000] acc: 0.34150001406669617\n",
      "[16, 1000] loss: 1.7960829926431179\n",
      "设备号为: tensor([ 2, 38,  2, 16], device='cuda:1')，预测的设备号为:tensor([35, 36,  2, 22], device='cuda:1')\n",
      "[16, 1000] acc: 0.3987500071525574\n",
      "[17, 1000] loss: 1.6754999904036523\n",
      "设备号为: tensor([44, 40, 22, 30], device='cuda:1')，预测的设备号为:tensor([44, 51, 14, 30], device='cuda:1')\n",
      "[17, 1000] acc: 0.43275001645088196\n",
      "[18, 1000] loss: 1.5932501022517682\n",
      "设备号为: tensor([50, 45, 31, 20], device='cuda:1')，预测的设备号为:tensor([42, 44, 31, 19], device='cuda:1')\n",
      "[18, 1000] acc: 0.4452500343322754\n",
      "[19, 1000] loss: 1.4886208862066268\n",
      "设备号为: tensor([46, 20, 16, 26], device='cuda:1')，预测的设备号为:tensor([46, 12, 21, 26], device='cuda:1')\n",
      "[19, 1000] acc: 0.4832500219345093\n",
      "[20, 1000] loss: 1.44839445219934\n",
      "设备号为: tensor([41, 40, 42, 50], device='cuda:1')，预测的设备号为:tensor([43, 49, 42, 50], device='cuda:1')\n",
      "[20, 1000] acc: 0.4932500123977661\n",
      "[21, 1000] loss: 1.3921424853503703\n",
      "设备号为: tensor([49, 29, 34, 40], device='cuda:1')，预测的设备号为:tensor([49, 35, 34, 49], device='cuda:1')\n",
      "[21, 1000] acc: 0.5157500505447388\n",
      "[22, 1000] loss: 1.3374837160259485\n",
      "设备号为: tensor([12, 50, 22, 50], device='cuda:1')，预测的设备号为:tensor([12, 50, 16, 50], device='cuda:1')\n",
      "[22, 1000] acc: 0.5235000252723694\n",
      "[23, 1000] loss: 1.3107802299037576\n",
      "设备号为: tensor([41, 53, 26, 19], device='cuda:1')，预测的设备号为:tensor([51, 53, 26, 20], device='cuda:1')\n",
      "[23, 1000] acc: 0.5365000367164612\n",
      "[24, 1000] loss: 1.2660748717188834\n",
      "设备号为: tensor([21,  3, 35, 47], device='cuda:1')，预测的设备号为:tensor([47,  7, 35, 22], device='cuda:1')\n",
      "[24, 1000] acc: 0.5625\n",
      "[25, 1000] loss: 1.205761055301875\n",
      "设备号为: tensor([10, 47, 12, 27], device='cuda:1')，预测的设备号为:tensor([ 8, 43, 12, 11], device='cuda:1')\n",
      "[25, 1000] acc: 0.5830000042915344\n",
      "[26, 1000] loss: 1.1557118675857783\n",
      "设备号为: tensor([22, 46, 22, 34], device='cuda:1')，预测的设备号为:tensor([21, 46, 30, 34], device='cuda:1')\n",
      "[26, 1000] acc: 0.5917500257492065\n",
      "[27, 1000] loss: 1.1159545346423985\n",
      "设备号为: tensor([12, 15, 28, 36], device='cuda:1')，预测的设备号为:tensor([15, 15, 31, 36], device='cuda:1')\n",
      "[27, 1000] acc: 0.6042500138282776\n",
      "[28, 1000] loss: 1.0770287475958467\n",
      "设备号为: tensor([24, 53, 47,  5], device='cuda:1')，预测的设备号为:tensor([24, 53, 43,  5], device='cuda:1')\n",
      "[28, 1000] acc: 0.6200000047683716\n",
      "[29, 1000] loss: 1.0541532900370658\n",
      "设备号为: tensor([22, 53, 21, 43], device='cuda:1')，预测的设备号为:tensor([19, 46, 16, 43], device='cuda:1')\n",
      "[29, 1000] acc: 0.6315000057220459\n",
      "[30, 1000] loss: 1.0018522447831928\n",
      "设备号为: tensor([35, 49, 22,  8], device='cuda:1')，预测的设备号为:tensor([35, 49, 18,  0], device='cuda:1')\n",
      "[30, 1000] acc: 0.6477500200271606\n",
      "[31, 1000] loss: 0.976019837025553\n",
      "设备号为: tensor([26, 15, 52, 10], device='cuda:1')，预测的设备号为:tensor([26, 15, 52, 38], device='cuda:1')\n",
      "[31, 1000] acc: 0.6605000495910645\n",
      "[32, 1000] loss: 0.9403177318796515\n",
      "设备号为: tensor([47, 14, 41, 29], device='cuda:1')，预测的设备号为:tensor([47, 14, 50, 29], device='cuda:1')\n",
      "[32, 1000] acc: 0.6792500615119934\n",
      "[33, 1000] loss: 0.9110704955942929\n",
      "设备号为: tensor([49, 27, 14,  5], device='cuda:1')，预测的设备号为:tensor([49, 27, 30,  6], device='cuda:1')\n",
      "[33, 1000] acc: 0.674750030040741\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "#             print(\"i:\", i )\n",
    "#             print(\"data: \", data[0])\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "#             inputs = inputs.permute(0, 2, 1)\n",
    "            \n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32, device = device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total = labels.size(0)\n",
    "#             print('原来的值:{0}, 预测的值:{1}'.format(labels, predicted))\n",
    "            running_correct = (predicted == labels).sum()\n",
    "            running_acc += running_correct\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 每loopNum个batch打印一次训练状态\n",
    "            loopNum = 1000\n",
    "            if i % loopNum == loopNum - 1:\n",
    "                average_loss = running_loss / loopNum\n",
    "                logger.info('[{0}, {1}] loss: {2}'.format(epoch + 1, i + 1, average_loss))\n",
    "                logger.info('设备号为: {0}，预测的设备号为:{1}'.format(labels, predicted))\n",
    "#                 logger.info(torch.cuda.current_device ())\n",
    "                running_acc = running_acc.float()\n",
    "                average_acc = running_acc / loopNum / total\n",
    "                \n",
    "                logger.info('[{0}, {1}] acc: {2}'.format(epoch + 1, i + 1, average_acc))\n",
    "                average_loss_series.append(average_loss)\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "\n",
    "    x = range(0, len(average_loss_series))\n",
    "    plt.figure()\n",
    "    plt.plot(x, average_loss_series)\n",
    "#     plt.savefig(\"Loss.png\")\n",
    "    plt.savefig(\"Loss.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # %%\n",
    "    # 在测试集上测试\n",
    "    realLabel = []\n",
    "    predictedLabel = []\n",
    "\n",
    "    def correct_rate(net, testloader):\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        count = 0\n",
    "        correctpredict = 0\n",
    "\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device),labels.to(device)\n",
    "            realLabel.append([int(label) for label in labels])\n",
    "    \n",
    "            tests = torch.tensor(images, dtype=torch.float32,device=device)\n",
    "            outputs = net(tests)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            logger.info('设备号为: {0}，模型训练后得到的设备号为:{1}'.format(labels, predicted))\n",
    "#             deviceNumber = torch.cuda.current_device ()\n",
    "#             logger.info(deviceNumber)\n",
    "            \n",
    "            labelsn = labels.cpu().numpy()\n",
    "            pn = predicted.cpu().numpy()\n",
    "            count += len(labelsn)\n",
    "            \n",
    "            for i in range(len(labelsn)):\n",
    "                if labelsn[i] == pn[i]:\n",
    "                    correctpredict += 1\n",
    "                \n",
    "            \n",
    "            logger.info('目前一共测试了{0}组，预测成功的一共有{1}组'.format(count, correctpredict))\n",
    "            predictedLabel.append([int(label) for label in predicted])\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "            \n",
    "        logger.info(\"total的值为：{total}\")\n",
    "#         return 100 * correct  # / total\n",
    "        return 100 * correct/ total \n",
    "\n",
    "\n",
    "    correct = correct_rate(net, test_loader)\n",
    "    logger.info(f'{len(test_loader) * 3}张测试集中准确率为： {correct}%')\n",
    "\n",
    "    # %%\n",
    "    import itertools\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    realLabel = list(itertools.chain.from_iterable(realLabel))\n",
    "    predictedLabel = list(itertools.chain.from_iterable(predictedLabel))\n",
    "\n",
    "    cm = confusion_matrix(realLabel, predictedLabel)\n",
    "    logger.info(cm)\n",
    "\n",
    "#     logger.info('the running time is:{1}'.format(time.time() - startTime))\n",
    "    torch.save(net.state_dict(), f'./model_每部分做希尔伯特_3.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5YnF55DLq90"
   },
   "outputs": [],
   "source": [
    "aa = iter(train_loader)\n",
    "a, b = aa.next()\n",
    "print(a[0].shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(20, 16, 50, 100)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2=nn.Conv2d(16,33,(3,5),stride=(2,1),padding=(4,2))\n",
    "inpu1=Variable(torch.randn(20,16,50,100))\n",
    "print(inpu1.shape)\n",
    "output=m2(inpu1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, len(average_loss_series))\n",
    "plt.figure()\n",
    "plt.plot(x, average_loss_series)\n",
    "plt.savefig(\"Loss-每部分做希尔伯特-3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "3_设计并训练神经网络.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
